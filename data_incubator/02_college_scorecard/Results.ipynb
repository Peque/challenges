{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Q1\n",
    "#\n",
    "\n",
    "# Load only 2013 data\n",
    "usecols = ['OPEID', 'ICLEVEL', 'UGDS', 'SAT_AVG']\n",
    "data = pandas.read_csv('CollegeScorecard_Raw_Data/MERGED2013_14_PP.csv',\n",
    "                       usecols=usecols)\n",
    "data = data.dropna()\n",
    "# Filter by 4-year college\n",
    "data = data[data['ICLEVEL'] == 1]\n",
    "# Admitted students approximation\n",
    "data['ADMITTED'] = data['UGDS'] / 4.\n",
    "# Calculate average SAT score\n",
    "data['SAT_TOTAL'] = data['SAT_AVG'] * data['ADMITTED']\n",
    "result = data['SAT_TOTAL'].sum() / data['ADMITTED'].sum()\n",
    "print('Q1: ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Q2\n",
    "#\n",
    "\n",
    "# Load only 2013 data\n",
    "usecols = ['ENRL_ORIG_YR2_RT', 'SAT_AVG']\n",
    "data = pandas.read_csv('CollegeScorecard_Raw_Data/MERGED2013_14_PP.csv',\n",
    "                       usecols=usecols)\n",
    "data['ENRL_ORIG_YR2_RT'] = pandas.to_numeric(data['ENRL_ORIG_YR2_RT'], errors='coerce')\n",
    "data = data.dropna()\n",
    "# Calculate Pearson correlation\n",
    "correlations = data.corr(method='pearson')\n",
    "result = correlations['SAT_AVG']['ENRL_ORIG_YR2_RT']\n",
    "print('Q2: ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Q3 & Q4\n",
    "#\n",
    "\n",
    "# Load only 2013 data\n",
    "columns = ['LO_INC_COMP_ORIG_YR4_RT', 'MD_INC_COMP_ORIG_YR4_RT', 'HI_INC_COMP_ORIG_YR4_RT']\n",
    "usecols = ['ICLEVEL'] + columns\n",
    "data = pandas.read_csv('CollegeScorecard_Raw_Data/MERGED2013_14_PP.csv',\n",
    "                       usecols=usecols)\n",
    "for column in columns:\n",
    "    data[column] = pandas.to_numeric(data[column], errors='coerce')\n",
    "data = data.dropna()\n",
    "# Filter by 4-year college\n",
    "data = data[data['ICLEVEL'] == 1]\n",
    "# Mean difference\n",
    "means = data.mean()\n",
    "result = means['HI_INC_COMP_ORIG_YR4_RT'] - means['LO_INC_COMP_ORIG_YR4_RT']\n",
    "print('Q3: ', result)\n",
    "\n",
    "# Perform t-test\n",
    "statistic, pvalue = ttest_ind(\n",
    "    data['LO_INC_COMP_ORIG_YR4_RT'],\n",
    "    data['HI_INC_COMP_ORIG_YR4_RT'],\n",
    "    equal_var=True)\n",
    "result = numpy.log10(pvalue)\n",
    "print('Q4: ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Q5\n",
    "#\n",
    "\n",
    "# Load only 2013 data\n",
    "columns = [\n",
    "    'UGDS_WHITE',\n",
    "    'UGDS_BLACK',\n",
    "    'UGDS_HISP',\n",
    "    'UGDS_ASIAN',\n",
    "    'UGDS_AIAN',\n",
    "    'UGDS_NHPI',\n",
    "    'UGDS_2MOR',\n",
    "    'UGDS_NRA',\n",
    "    'UGDS_UNKN',\n",
    "    'UGDS_WHITENH',\n",
    "    'UGDS_BLACKNH',\n",
    "    'UGDS_API',\n",
    "    'UGDS_AIANOLD',\n",
    "    'UGDS_HISPOLD',\n",
    "]\n",
    "data = pandas.read_csv('CollegeScorecard_Raw_Data/MERGED2013_14_PP.csv',\n",
    "                       usecols=columns)\n",
    "# Filter valid entries\n",
    "data = data[data.max(axis=1) > 0.]\n",
    "# Minimum difference\n",
    "diff = data.max(axis=1) - data.min(axis=1)\n",
    "result = diff.min()\n",
    "print('Q5: ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Q6\n",
    "#\n",
    "\n",
    "# Load data between 2001 and 2010\n",
    "columns = ['OPEID', 'UGDS_WOMEN']\n",
    "data = []\n",
    "for i in range(1, 11):\n",
    "    csv = 'CollegeScorecard_Raw_Data/MERGED20%02d_%02d_PP.csv' % (i, i + 1)\n",
    "    df = pandas.read_csv(csv, usecols=columns, index_col='OPEID', low_memory=False)\n",
    "    df = df.rename(columns={'UGDS_WOMEN': str(i)})\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    data.append(df)\n",
    "data = pandas.concat(data, axis=1).dropna()\n",
    "# Calculate average share of enrollment\n",
    "result = data.mean().mean()\n",
    "print('Q6: ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Q7\n",
    "#\n",
    "\n",
    "# Load all data\n",
    "columns = ['OPEID', 'REGION', 'LOCALE']\n",
    "data = None\n",
    "for i in range(2014, 1995, -1):\n",
    "    csv = 'CollegeScorecard_Raw_Data/MERGED%s_%s_PP.csv' % (i, str(i + 1)[-2:])\n",
    "    df = pandas.read_csv(csv, usecols=columns, low_memory=False)\n",
    "    df = df.dropna()\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    if data is None:\n",
    "        data = df\n",
    "    else:\n",
    "        diff = set(df.index) - set(data.index)\n",
    "        df = df.iloc[pandas.Series(list(diff))]\n",
    "        data = pandas.concat([data, df])\n",
    "# Clean data a bit\n",
    "data['LOCALE'] = data['LOCALE'].astype('int')\n",
    "data['CITY'] = data['LOCALE'].between(11, 13).astype('int')\n",
    "data = data.drop(['OPEID', 'LOCALE'], axis=1)\n",
    "# Calculate max probability\n",
    "probs = data.groupby('REGION').sum() / data.groupby('REGION').count()\n",
    "result = probs.max()['CITY']\n",
    "print('Q7: ', result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
